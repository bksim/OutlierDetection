<!DOCTYPE html>
<!--[if lt IE 7 ]><html class="ie ie6" lang="en"> <![endif]-->
<!--[if IE 7 ]><html class="ie ie7" lang="en"> <![endif]-->
<!--[if IE 8 ]><html class="ie ie8" lang="en"> <![endif]-->
<!--[if (gte IE 9)|!(IE)]><!--><html lang="en"> <!--<![endif]-->
<head>

	<!-- Basic Page Needs
  ================================================== -->
	<meta charset="utf-8">
	<title>Outlier Detection</title>
	<meta name="description" content="">
	<meta name="author" content="">

	<!-- Mobile Specific Metas
  ================================================== -->
	<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

	<!-- CSS
  ================================================== -->
	<link rel="stylesheet" href="stylesheets/base.css">
	<link rel="stylesheet" href="stylesheets/skeleton.css">
	<link rel="stylesheet" href="stylesheets/layout.css">
	<link rel="stylesheet" href="stylesheets/default.css">


	<!--[if lt IE 9]>
		<script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
	<![endif]-->

	<script type="text/x-mathjax-config">
	  MathJax.Hub.Config({
	    tex2jax: {
	      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
	      processEscapes: true
	    }
	  });
	</script>
	<script type="text/javascript"
	    src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
	</script>

	<!-- Favicons
	================================================== -->
	<link rel="shortcut icon" href="images/favicon.ico">
	<link rel="apple-touch-icon" href="images/apple-touch-icon.png">
	<link rel="apple-touch-icon" sizes="72x72" href="images/apple-touch-icon-72x72.png">
	<link rel="apple-touch-icon" sizes="114x114" href="images/apple-touch-icon-114x114.png">

	<script src="js/jquery-1.11.0.min.js"></script>
	<script src="js/lightbox.min.js"></script>
	<link href="css/lightbox.css" rel="stylesheet" />

</head>
<body>



	<!-- Primary Page Layout
	================================================== -->

	<!-- Delete everything in this .container and get started on your own site! -->

	<!--<div class="container">
		<div class="sixteen columns">
			<h1 class="remove-bottom" style="margin-top: 40px">Skeleton</h1>
			<h5>Version 1.2</h5>
			<hr />
		</div>
		<div class="one-third column">
			<h3>About Skeleton?</h3>
			<p>Skeleton is a small collection of well-organized CSS files that can help you rapidly develop sites that look beautiful at any size, be it a 17" laptop screen or an iPhone. It's based on a responsive grid, but also provides very basic CSS for typography, buttons, forms and media queries. Go ahead, resize this super basic page to see the grid in action.</p>
		</div>
		<div class="one-third column">
			<h3>Three Core Principles</h3>
			<p>Skeleton is built on three core principles:</p>
			<ul class="square">
				<li><strong>A Responsive Grid Down To Mobile</strong>: Elegant scaling from a browser to tablets to mobile.</li>
				<li><strong>Fast to Start</strong>: It's a tool for rapid development with best practices</li>
				<li><strong>Style Agnostic</strong>: It provides the most basic, beautiful styles, but is meant to be overwritten.</li>
			</ul>
		</div>
		<div class="one-third column">
			<h3>Docs &amp; Support</h3>
			<p>The easiest way to really get started with Skeleton is to check out the full docs and info at <a href="http://www.getskeleton.com">www.getskeleton.com.</a>. Skeleton is also open-source and has a <a href="https://github.com/dhgamache/skeleton">project on git</a>, so check that out if you want to report bugs or create a pull request. If you have any questions, thoughts, concerns or feedback, please don't hesitate to email me at <a href="mailto:hi@getskeleton.com">hi@getskeleton.com</a>.</p>
		</div>

	</div>-->
	<!-- container -->

	<div class="main container">
		<div class="row">
			<div class="three columns sidebar">
				<div id="nav">
					<h4 class="hero">Navigation</h4>
					<a href="./index.html">Home</a>
					<a href="./motivation.html">Motivation</a>
					<a href="./data.html">Data &amp; Initial Exploration</a>
					<a href="./methods.html">Previous Work &amp; Methods</a>
					<a href="./results.html">Mixture of Experts &amp; Results</a>
				</div>
			</div>

			<div id="content" class="nine columns">
				<h4 class="title">Mixture of Experts &amp; Results</h4>
				<h5>Introduction to the Mixture of Experts</h5>
				<p>With the mixture of experts approach, we assume that each outlier detection method performs best within a particular domain of the sample space. In this ensemble method, we combine the results from each method in a smart way so that the diversity of experts can make up for deficiencies in individual methods over particular domains. Therefore, the result of each expert is weighted by values generated based on the location of the point in the 57-dimensional space. The gating parameter $\eta_i$ for each expert $i$ must be trained. </p>

				<img src="images/Results0.png" width="50%" style="margin-left: auto; margin-right: auto; display: block;margin-bottom:15px;"/>
				<p class="caption"><strong>Figure R1. Mixture of Experts. </strong> The result of each expert is weighted by values generated from a gating network. Both the gating network and the experts must be trained.</p>

				<p>The gating probability $g_i^x$ is the weight assigned to each expert $i$ for data point $\vec{x}$. The weights are generated using a soft-max gating network:
					$$g_i^x= \frac{exp(\vec{\eta_i}^T \vec{x})}{\sum_{j=1}^k exp(\vec{\eta_j}^T \vec{x}) },$$
					where $\vec{x}$ is a 57-dimensional data vector (one data point), and $\eta_i$ is the gating parameter for each expert $i$, with a total of $k$ experts. Thus, the outlierliness score $P_x$ for a particular data point $\vec{x}$ is:
					$$P_x = \sum_{i=1}^k g_i(\vec{\eta_j},\vec{x}) p_i(\vec{x}),$$
					where $p_i(\vec{x})$ is the outlierliness score assigned to a particular data point $\vec{x}$ by expert/model $i$.
				</p>


				<h5>Results</h5>
				<p>A mixture of experts model was trained on the current data set, optimizing for the detection of the artificial and the rcb group outliers. The optimization is done using simulated annealing over the entire range of possible $\eta$ values.</p>
				<a href='images/Results1.png' data-lightbox='Results1'>
				<img src="images/Results1.png" width="70%" style="margin-left: auto; margin-right: auto; display: block;margin-bottom:15px;"/></a>
				<p class="caption"><strong>Figure R2. ROC for the combined mixture of experts outlier detection method. </strong> While the combined model does better in detecting rcb outliers, the results here suggest that a mixture of experts approach performs better than individual experts separately.</p>

				<p>As shown above, the mixture of experts ensemble method is able to perform better (in most cases) than any of the individual outlier detection methods discussed in the previous section. Cases where it does similarly or worse than  individual outlier detection methods can be explained by our optimizing of <em>both</em> the rcb and the artificial outlier detection. The simultaneous optimization of two factors may have lead to a compromises in the absolute performance for each specific outlier class. </p>

					<table>
					  <thead>
					    <tr>
					      <th>Method</th>
					      <th>Artificial Outliers AUC</th>
					      <th>RCB Outliers AUC</th>
					      <th>Average AUC</th>
					    </tr>
					  </thead>
					  <tbody>
					    <tr>
					      <td>KNN 1 I-channel</td>
					      <td>0.85</td>
					      <td>0.94</td>
					      <td>0.90</td>
					    </tr>
					    <tr>
					      <td>KNN 1 V-channel</td>
					      <td>0.42</td>
					      <td>0.88</td>
					      <td>0.65</td>
					    </tr>
					    <tr>
					      <td>KNN 2 I-channel</td>
					      <td>0.50</td>
					      <td><strong>0.95</strong></td>
					      <td>0.73</td>
					    </tr>
					    <tr>
					      <td>KNN 2 V-channel</td>
					      <td>0.50</td>
					      <td>0.68</td>
					      <td>0.59</td>
					    </tr>
					    <tr>
					      <td>SVM+JP I-channel</td>
					      <td>0.78</td>
					      <td>0.91</td>
					      <td>0.85</td>
					    </tr>
					    <tr>
					      <td>SVM+JP V-channel</td>
					      <td>0.62</td>
					      <td>0.73</td>
					      <td>0.68</td>
					    </tr>
					    <tr>
					      <td>LOCI I-channel</td>
					      <td>0.30</td>
					      <td>0.28</td>
					      <td>0.29</td>
					    </tr>
					    <tr>
					      <td>LOCI V-channel</td>
					      <td>0.28</td>
					      <td>0.45</td>
					      <td>0.37</td>
					    </tr>
					    <tr>
					      <td>Hyperplane I-channel</td>
					      <td>0.78</td>
					      <td>0.78</td>
					      <td>0.78</td>
					    </tr>
					    <tr>
					      <td>Hyperplane V-channel</td>
					      <td><strong>0.99</strong></td>
					      <td>0.82</td>
					      <td><strong>0.91</strong></td>
					    </tr>
					    <tr>
					      <td>Mixture of Experts</td>
					      <td>0.99</td>
					      <td>0.89</td>
					      <td>0.94</td>
					    </tr>
					   </tbody>
					</table>
				<p class="caption"><strong>Table R1. Area under the ROC curve (AUC) for various outlier detection methods.</strong> The AUC was used as a single-number metric to compare between ROC cruves (such as those seen in the Methods section). Bolded AUC values are from the outlier detection method that did the best under each outlier detection task (either detecing artificial outliers or the rcb class as outliers). </p>

				<p>Table R1 shows the performance (as measured by AUC of the ROC curve) for each expert along with the performance of the mixture of experts. Since the mixture of experts is optimized for both artificial and rcb class outliers, it seems intuitive that the performance of detecting one type of outlier may be sacrificed for overall performance of both outliers. Thus, it makes sense that the average AUC for the mixture of experts is highest, but we would nto necessarily expect to see highest performance in detection of both artificial and rcb class outliers. However, the mixture still seems to be able to maintain high performance for the artificial outlier detection. </p>

				<a href='images/Results2.png' data-lightbox='Results2'>
				<img src="images/Results2.png" width="70%" style="margin-left: auto; margin-right: auto; display: block;margin-bottom:15px;"/></a>
				<p class="caption"><strong>Figure R3. Data points with detected outliers plotted on the PCA plane (I-channel).</strong> Detected outliers are outlied in yellow. The threshold 1.1 was chosen by eye such that the obvious outliers were identified, yet not many points in the main cluster were identified as outlier. The false positive rate at this threshold is 1% and the true postive rate is 68%.</p>

				<p>As can be seen, the mixture of experts model is able to identify almost all of the class rcb that appear to be far away frpm the other points on the PCA plane. With this threshold (1.1) the false positive rate is 1% and the true postive rate is 68%. Of course, depending on one's tolerance for type 1 or type 2 error, the threshold can be adjusted. </p>

				<h5>Application to Larger Data Set</h5>
				<p>We used out mixture of expert model trained with the 1913 outliers to detect outliers in the larger data set of 19812 light curves: 5344 from lpv, 1252 from dsct, 5365 from ecl, 202 from t2cep, 2139 from cep, 82 from acep, 5270 from rrlyr, 22 from rcb, and 136 from dpv. This set includes the training set. Note that the number of rcb class outliers is the same as the training set, so this exercise will show the performance of the mixture model in identifying the rcb class while dealing with more non-outlier data. </p>

				<a href='images/Results3.png' data-lightbox='Results3'>
				<img src="images/Results3.png" width="70%" style="margin-left: auto; margin-right: auto; display: block;margin-bottom:15px;"/></a>
				<p class="caption"><strong>Figure R4. ROC for the combined mixture of experts outlier detection method. </strong> While the combined model does better in detecting rcb outliers, the results here suggest that a mixture of experts approach performs better than individual experts separately.</p>

				<a href='images/Results4.png' data-lightbox='Results4'>
				<img src="images/Results4.png" width="70%" style="margin-left: auto; margin-right: auto; display: block;margin-bottom:15px;"/></a>
				<p class="caption"><strong>Figure R5. Data points with detected outliers plotted on the PCA plane (I-channel).</strong> Detected outliers are outlied in yellow. The threshold 1.1 was chosen by eye such that the obvious outliers were identified, yet not many points in the main cluster were identified as outlier. The false positive rate at this threshold is 1% and the true postive rate is 68%.</p>

				<h5>Next Steps</h5>
				<p>Future work should focus on the addition of more outlier detection "experts" to the model. In addition, the optimization of the gating parmeter $\eta$ in mixture of experts model may be optimized simultaneously with individual expert parameters using expectation maximization and stochastic gradient descent. In addition, we look to use our easily extensible code to extend our work to other domains - in particular, fraud detection in financial transaction networks, which we hope to look at next semester.</p>
			</div>
		</div>
	</div><!-- container -->

<!-- End Document
================================================== -->
</body>
</html>