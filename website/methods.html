<!DOCTYPE html>
<!--[if lt IE 7 ]><html class="ie ie6" lang="en"> <![endif]-->
<!--[if IE 7 ]><html class="ie ie7" lang="en"> <![endif]-->
<!--[if IE 8 ]><html class="ie ie8" lang="en"> <![endif]-->
<!--[if (gte IE 9)|!(IE)]><!--><html lang="en"> <!--<![endif]-->
<head>

	<!-- Basic Page Needs
  ================================================== -->
	<meta charset="utf-8">
	<title>Outlier Detection</title>
	<meta name="description" content="">
	<meta name="author" content="">

	<!-- Mobile Specific Metas
  ================================================== -->
	<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

	<!-- CSS
  ================================================== -->
	<link rel="stylesheet" href="stylesheets/base.css">
	<link rel="stylesheet" href="stylesheets/skeleton.css">
	<link rel="stylesheet" href="stylesheets/layout.css">
	<link rel="stylesheet" href="stylesheets/default.css">


	<!--[if lt IE 9]>
		<script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
	<![endif]-->

	<script type="text/x-mathjax-config">
	  MathJax.Hub.Config({
	    tex2jax: {
	      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
	      processEscapes: true
	    }
	  });
	</script>
	<script type="text/javascript"
	    src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
	</script>

	<!-- Favicons
	================================================== -->
	<link rel="shortcut icon" href="images/favicon.ico">
	<link rel="apple-touch-icon" href="images/apple-touch-icon.png">
	<link rel="apple-touch-icon" sizes="72x72" href="images/apple-touch-icon-72x72.png">
	<link rel="apple-touch-icon" sizes="114x114" href="images/apple-touch-icon-114x114.png">

	<script src="js/jquery-1.11.0.min.js"></script>
	<script src="js/lightbox.min.js"></script>
	<link href="css/lightbox.css" rel="stylesheet" />
</head>
<body>



	<!-- Primary Page Layout
	================================================== -->

	<!-- Delete everything in this .container and get started on your own site! -->

	<!--<div class="container">
		<div class="sixteen columns">
			<h1 class="remove-bottom" style="margin-top: 40px">Skeleton</h1>
			<h5>Version 1.2</h5>
			<hr />
		</div>
		<div class="one-third column">
			<h3>About Skeleton?</h3>
			<p>Skeleton is a small collection of well-organized CSS files that can help you rapidly develop sites that look beautiful at any size, be it a 17" laptop screen or an iPhone. It's based on a responsive grid, but also provides very basic CSS for typography, buttons, forms and media queries. Go ahead, resize this super basic page to see the grid in action.</p>
		</div>
		<div class="one-third column">
			<h3>Three Core Principles</h3>
			<p>Skeleton is built on three core principles:</p>
			<ul class="square">
				<li><strong>A Responsive Grid Down To Mobile</strong>: Elegant scaling from a browser to tablets to mobile.</li>
				<li><strong>Fast to Start</strong>: It's a tool for rapid development with best practices</li>
				<li><strong>Style Agnostic</strong>: It provides the most basic, beautiful styles, but is meant to be overwritten.</li>
			</ul>
		</div>
		<div class="one-third column">
			<h3>Docs &amp; Support</h3>
			<p>The easiest way to really get started with Skeleton is to check out the full docs and info at <a href="http://www.getskeleton.com">www.getskeleton.com.</a>. Skeleton is also open-source and has a <a href="https://github.com/dhgamache/skeleton">project on git</a>, so check that out if you want to report bugs or create a pull request. If you have any questions, thoughts, concerns or feedback, please don't hesitate to email me at <a href="mailto:hi@getskeleton.com">hi@getskeleton.com</a>.</p>
		</div>

	</div>-->
	<!-- container -->

	<div class="main container">
		<div class="row">
			<div class="three columns sidebar">
				<div id="nav">
					<h4 class="hero">Navigation</h4>
					<a href="./index.html">Home</a>
					<a href="./motivation.html">Motivation</a>
					<a href="./data.html">Data &amp; Initial Exploration</a>
					<a href="./methods.html">Previous Work &amp; Methods</a>
					<a href="./results.html">Mixture of Experts &amp; Results</a>
				</div>
			</div>

			<div id="content" class="nine columns">
				<h4 class="title">Previous Work &amp; Methods</h4>
				<p>The Mixture of Experts approach gets its strength from combining the output of separate methods (experts) having presumably different regimes of expertise.</p>

				<p>In this project, five outlier detection methods (modified and/or unmodified from previous work) were used on either the infrared (I) or visual (V) channels of the light curves. This gave a total of ten experts (five methods on two different channels). Here, we describe each outlier detection method and show its stand-alone performance. </p>

				<p>We measure performance using two metrics. First, an artificial set of outliers are created (see below) and the method's ability to score them as outliers is measured. In the second method, we choose a class ('rcb') that is designated as outlier (based on initial data exploration). We then evaulate how well the method can score objects in this class as outliers. </p>

				<h5>Creation of Artificial Outliers</h5>
				<p>20 artificial outliers were created by first randomly sampling 20 light curves from the data set. Within each feature, the 20 values were randomly shuffled among the data points. Then, $n$ standard deviations (of each feature) were randomly added to each data value, where $n$ is selected from a standard normal distribution centered at 4. Figure P1 shows the outliers plotted on the PCA plane.</p>
				<a href='images/Methods1.png' data-lightbox='Methods1'>
					<img src="images/Methods1.png" width="100%"/>
				</a>
				<p class="caption"><strong>Figure P1. Artificial Outliers on the PCA plane, along with real data.</strong> 20 Artificial outliers (white dots, black outline) were created as described. The outliers do not seem too far removed from the main cluster of points on the PCA plane, indicating that measuring outlier detection performance with these artificial points will provide a good test of robustness of each method. </p>

				<h5>K Nearest Neighbors 1 (KNN1)</h5>
				<p>Modified from ??????. Description of what this method is. <mark>[Brandon]</mark> </p>

			
				<a href='images/knn1.png' data-lightbox='knn1'>
					<img src="images/knn1.png"/>
				</a>
				<p class="caption"><strong>Figure P2. Visual representation .</strong> description... </p>

				<a href='images/Methods2.png' data-lightbox='Methods2'>
					<img src="images/Methods2.png" width="100%"/>
				</a>
				<p class="caption"><strong>Figure P3. ROC for the KNN1 method.</strong> description... </p>


				<h5>K Nearest Neighbors 2 (KNN2)</h5>
				<p>Modified from ??????. Description of what this method is. <mark>[Brandon]</mark> </p>

				<center>
				<a href='images/knn2.png' data-lightbox='knn2'>
					<img src="images/knn2.png"/>
				</a>
				<p class="caption"><strong>Figure P4. Visual Representation of KNN2.</strong> description... </p>
				</center>
				<a href='images/Methods3.png' data-lightbox='Methods3'>
					<img src="images/Methods3.png" width="100%"/>
				</a>
				<p class="caption"><strong>Figure P5. ROC for the KNN2 method.</strong> description... </p>


				<h5>Support Vector Machine &amp; Joint Probability (SVM+JP)</h5>
				<p>This is a supervised learning method modified from <a href="http://iopscience.iop.org/0004-637X/793/1/23">Nun et al. 2014</a> and documented by supervised-learning standard algorithms. Briefly, a classifier is trained on data with known class labels. For each point, a membership probability vector is produced that lists the probability of its belonging to each class. Then a joint probability for the particular combination of membership probabilities is calculated.  Nun et al. used a random forest classifier and a Bayesian Network to produce the joint probabilities. Outliers are then identified as the points that have low joint probabilities because class membership probability vectors similar to thiers were not been seen often enough in the training data. </p>
				<p>Here, we modify the approach by using SVM (rbf kernel) for the classifier and a frequency table to determine the joint probabilities. In addition, an artificial class sampled uniformly from the sample space was used to train the classifier. The outlier class combined used in conjuction with the rbf kernel SVM allowed the method to create bounded regions for each class even with a very small number randomly sampled background. These modifications were found to improve outlier detection (especially excluded-group outliers).  We can see a small-scale example on the classic "Iris" data set, below. </p>
				<p>SVM was used instead of random forest because it can draws neater and tighter decision boundaries around clusters of points. This is necessary because outliers can be positioned far away from the initial training data points, yet be classified under a particular class solely due to its position radial to a class decision space. We found that the SVM classifier, with decision boundaries that encompass well the clusters of points for each particular class, improves detection of these kinds of outliers. </p>

				<a href='images/svmiris.jpg' data-lightbox='svmiris'>
					<img src="images/svmiris.jpg" width="100%"/>
				</a>

				<p class="caption"><strong>Figure P6. RBF Kernel SVM on Iris Data </strong> Quote Quote </p>


				<h5>Local Correlation Integral (LoCI)</h5>
				<p>Modified from Papdimitriou et al. 201?.</p>
				<a href='images/Methods5.png' data-lightbox='Methods5'>
					<img src="images/Methods5.png" width="100%"/>
				</a>
				<p class="caption"><strong>Figure P7. ROC for the LOCI method. <mark>[Brandon]</mark></strong> description... </p>



				<h5>Mixture Model (Eskin)</h5>
				<p>Modified from <a href="http://academiccommons.columbia.edu/download/fedora_content/download/ac:125814/CONTENT/anomaly-icml00.pdf">Eskin, 2000</a>.</p>

				<center>
				<a href='images/mixturemodel.jpg' data-lightbox='mixturemodel'>
					<img src="images/mixturemodel.jpg" width="60%"/>
				</a>
				<p class="caption"><strong>Figure P8. Mixture Model Visual.</strong> description... </p>
				</center>

				<a href='images/Methods6.png' data-lightbox='Methods6'>
					<img src="images/Methods6.png" width="100%"/>
				</a>
				<p class="caption"><strong>Figure P9. ROC for the Eskin method. <mark>[Wes]</mark></strong> description... </p>


			</div>
		</div>
	</div><!-- container -->

<!-- End Document
================================================== -->
</body>
</html>