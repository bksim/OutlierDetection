<!DOCTYPE html>
<!--[if lt IE 7 ]><html class="ie ie6" lang="en"> <![endif]-->
<!--[if IE 7 ]><html class="ie ie7" lang="en"> <![endif]-->
<!--[if IE 8 ]><html class="ie ie8" lang="en"> <![endif]-->
<!--[if (gte IE 9)|!(IE)]><!--><html lang="en"> <!--<![endif]-->
<head>

	<!-- Basic Page Needs
  ================================================== -->
	<meta charset="utf-8">
	<title>Outlier Detection</title>
	<meta name="description" content="">
	<meta name="author" content="">

	<!-- Mobile Specific Metas
  ================================================== -->
	<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

	<!-- CSS
  ================================================== -->
	<link rel="stylesheet" href="stylesheets/base.css">
	<link rel="stylesheet" href="stylesheets/skeleton.css">
	<link rel="stylesheet" href="stylesheets/layout.css">
	<link rel="stylesheet" href="stylesheets/default.css">


	<!--[if lt IE 9]>
		<script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
	<![endif]-->

	<script type="text/x-mathjax-config">
	  MathJax.Hub.Config({
	    tex2jax: {
	      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
	      processEscapes: true
	    }
	  });
	</script>
	<script type="text/javascript"
	    src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
	</script>

	<!-- Favicons
	================================================== -->
	<link rel="shortcut icon" href="images/favicon.ico">
	<link rel="apple-touch-icon" href="images/apple-touch-icon.png">
	<link rel="apple-touch-icon" sizes="72x72" href="images/apple-touch-icon-72x72.png">
	<link rel="apple-touch-icon" sizes="114x114" href="images/apple-touch-icon-114x114.png">

</head>
<body>



	<!-- Primary Page Layout
	================================================== -->

	<!-- Delete everything in this .container and get started on your own site! -->

	<!--<div class="container">
		<div class="sixteen columns">
			<h1 class="remove-bottom" style="margin-top: 40px">Skeleton</h1>
			<h5>Version 1.2</h5>
			<hr />
		</div>
		<div class="one-third column">
			<h3>About Skeleton?</h3>
			<p>Skeleton is a small collection of well-organized CSS files that can help you rapidly develop sites that look beautiful at any size, be it a 17" laptop screen or an iPhone. It's based on a responsive grid, but also provides very basic CSS for typography, buttons, forms and media queries. Go ahead, resize this super basic page to see the grid in action.</p>
		</div>
		<div class="one-third column">
			<h3>Three Core Principles</h3>
			<p>Skeleton is built on three core principles:</p>
			<ul class="square">
				<li><strong>A Responsive Grid Down To Mobile</strong>: Elegant scaling from a browser to tablets to mobile.</li>
				<li><strong>Fast to Start</strong>: It's a tool for rapid development with best practices</li>
				<li><strong>Style Agnostic</strong>: It provides the most basic, beautiful styles, but is meant to be overwritten.</li>
			</ul>
		</div>
		<div class="one-third column">
			<h3>Docs &amp; Support</h3>
			<p>The easiest way to really get started with Skeleton is to check out the full docs and info at <a href="http://www.getskeleton.com">www.getskeleton.com.</a>. Skeleton is also open-source and has a <a href="https://github.com/dhgamache/skeleton">project on git</a>, so check that out if you want to report bugs or create a pull request. If you have any questions, thoughts, concerns or feedback, please don't hesitate to email me at <a href="mailto:hi@getskeleton.com">hi@getskeleton.com</a>.</p>
		</div>

	</div>-->
	<!-- container -->

	<div class="main container">
		<div class="three columns sidebar">
			<div id="nav">
				<h4 class="hero">Navigation</h4>
				<a href="./index.html">Home</a>
				<a href="./motivation.html">Motivation</a>
				<a href="./data.html">Data &amp; Initial Exploration</a>
				<a href="./methods.html">Previous Work &amp; Methods</a>
				<a href="./results.html">Results</a>
			</div>
		</div>

		<div id="content" class="twelve columns offset-by-one">
			<h4 class="title">Previous Work &amp; Methods</h4>
			<p>The Mixture of Experts approach gets its strength from combining the output of separate methods (experts) having presumably different regimes of expertise.</p>

			<p>In this project, five oulier detection methods (modified and/or unmodified from previous work) were used on either the infrared (I) or visual (V) channels of the light curves. This gave a total of ten experts (five methods on two different channels). Here, we describe each outlier detection method and show its stand-alone performance. </p>

			<p>We measure performance using two metrics. First, an artificial set of outliers are created (see below) and the method's ability to score them as outliers is measured. In the second method, we choose a class ('rcb') that is designated as outlier (based on initial data exploration). We then evaulate how well the method can score objects in this class as outliers. </p>

			<h5>Creation of Artificial Outliers</h5>
			<p>20 artificial outliers were created by first randomly sampling 20 light curves from the data set. Within each feature, the 20 values were randomly shuffled among the data points. Then, $n$ standard deviations (of each feature) were randomly added to each data value, where $n$ is selected from a standard normal distribution centered at 4. Figure P1 shows the outliers plotted on the PCA plane.</p>
			<img src="images/Methods1.png" width="100%"/>
			<p class="caption"><strong>Figure P1. Artificial Outliers on the PCA plane, along with real data.</strong> 20 Artificial outliers (white dots, black outline) were created as described. The outliers do not seem too far removed from the main cluster of points on the PCA plane, indicating that measuring outlier detection performance with these artificial points will provide a good test of robustness of each method. </p>



			<h5>K Nearest Neighbors 1 (KNN1)</h5>
			<p>Modified from ??????. Description of what this method is. <mark>[Brandon]</mark> </p>
			<img src="images/Methods2.png" width="100%"/>
			<p class="caption"><strong>Figure P2. ROC for the KNN1 method.</strong> description... </p>



			<h5>K Nearest Neighbors 2 (KNN2)</h5>
			<p>Modified from ??????. Description of what this method is. <mark>[Brandon]</mark> </p>
			<img src="images/Methods3.png" width="100%"/>
			<p class="caption"><strong>Figure P3. ROC for the KNN2 method.</strong> description... </p>


			<h5>Support Vector Machine &amp; Joint Probability (SVM+JP)</h5>
			<p>This is a supervised learning method modified from <a href="http://iopscience.iop.org/0004-637X/793/1/23">Nun et al. 2014</a>. Breifly, a classifier is trained on data with known class labels. For each point, a membership probability vector is produced that lists the probability of its belonging to each class. Then a joint probability for the particular combination of membership probabilities is calculated.  Nun et al. used a random forest classifier and a Bayesian Network to produce the joint probabilities. Outliers are then identified as the points that have low joint probabilities because class membership probability vectors similar to thiers were not been seen often enough in the training data. </p>
			<p>Here, we modify the approach by using SVM (rbf kernel) for the classifier and a frequency table to determine the joint probabilities. In addition, an artificial class sampled uniformly from the sample space was used to train the classifier but excluded in the joint probability calculations. These modifications were found to improve outlier detection (especially excluded-group outliers) in our data set.</p>
			<p>SVM was used instead of random forest because it can draw tigher decision boundaries around clusters of points in the same class when given an added artificial uniformly sampled class. This is necessary because outliers can be positioned far away from the initial training data points, yet be classified under a particular class solely due to its position radial to a class decision space. We found that the SVM classifier, with decision boundaries that encompass well the clusters of points for each particular class, improves detection of these kinds of outliers. </p>
			<p>A joint probability table (with 9 bins of discretization) was used in the determination of joint probabilities in the interest of computational speed and clarity. Formulating this part of the method using a Bayesian Network may be explored in future work.</p>
			<img src="images/Methods4.png" width="100%"/>
			<p class="caption"><strong>Figure P4. ROC for the SVM+JP method. </strong> In the infrared channel (left), the SVM+JP method does very well in identifying the rcb outliers, whereas it does not do significantly better than random guessing for the artificial outliers. In the visible channel (left), there is poorer performance for the rcb data. </p>



			<h5>Local Correlation Integral (LoCI)</h5>
			<p>Modified from Papdimitriou et al. 201?.</p>
			<img src="images/Methods5.png" width="100%"/>
			<p class="caption"><strong>Figure P5. ROC for the LOCI method. <mark>[Brandon]</mark></strong> description... </p>



			<h5>Eskin (Eskin)</h5>
			<p>Modified from Eskin et al. 201?.</p>
			<img src="images/Methods6.png" width="100%"/>
			<p class="caption"><strong>Figure P6. ROC for the Eskin method. <mark>[Wes]</mark></strong> description... </p>


		</div>
	</div><!-- container -->

<!-- End Document
================================================== -->
</body>
</html>